{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'code_scripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d23e34e13ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'code_scripts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'code_scripts'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import cv2\n",
    "from math import pi\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from skimage.measure import block_reduce\n",
    "from scipy.ndimage import rotate, convolve, sobel, laplace\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "#from ksvd import ApproximateKSVD\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir('code_scripts')\n",
    "import visualization as viz\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing : creating LR images and denoising (Rician noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'HR_data/'\n",
    "\n",
    "HR_ref = np.load(data_path+'image1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Low Resolution Image with mean downsampling\n",
    "LR_img = block_reduce(HR_ref, block_size=(1,1,2), func=np.mean)\n",
    "\n",
    "# Low Resolution Image with max downsampling\n",
    "LR_img = block_reduce(HR_ref, block_size=(1,1,2), func=np.max)\n",
    "\n",
    "# Interpolate low resolution image to high resolution shape\n",
    "LR_img_interp = resize(LR_img, output_shape=HR_ref.shape, mode='symmetric', order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Super-Resolution Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Takes original, upsampled MRI image and generates a rotated y0, y_a0, and y_s0\n",
    "    \n",
    "    Params: original_image = original, upsampled (via cubic spline) MRI image\n",
    "            kernel = rect function kernel \n",
    "            rotation_degree = degree of rotation that you want\n",
    "          \n",
    "    Return: rotated_image = R(y0), where R = rotation matrix\n",
    "            image_a0 = upsampled y0 that is convolved with the rotated kernel\n",
    "            image_s0 = R(y0) that is convolved with the non-rotated kernel\n",
    "'''\n",
    "def generate_rotated_images(original_img, kernel, rotation_degree):\n",
    "    \n",
    "    # Rotate original image by the given degree\n",
    "    rotated_image = rotate(original_img, rotation_degree, reshape = False)\n",
    "    \n",
    "    # Rotate rect function kernel\n",
    "    rotated_kernel = rotate(kernel, rotation_degree, reshape = False)\n",
    "    rotated_kernel = np.where(rotated_kernel > 0.1, 1, 0)\n",
    "    \n",
    "    # Create empty arrays for y_a0 and y_s0 in the original paper\n",
    "    image_a0 = np.zeros(shape = original_img.shape)\n",
    "    image_s0 = np.zeros(shape = original_img.shape)\n",
    "    \n",
    "    # Fill in the arrays with the convolved images\n",
    "    # image_a0 = rotated kernel convolved with original image\n",
    "    # image_s0 = original kernel convolved with rotated image\n",
    "    for i in range(original_img.shape[2]):\n",
    "        image_a0[:,:,i] = convolve(original_img[:,:,i], rotated_kernel)\n",
    "        image_s0[:,:,i] = convolve(rotated_image[:,:,i], kernel)\n",
    "    \n",
    "    return rotated_image, image_a0, image_s0\n",
    "\n",
    "\n",
    "'''\n",
    "    Computes first and second gradient images of y_a0 in all 3 directions \n",
    "    using Sobel filter for 1st deriv (scipy.ndimage.sobel) and Laplacian filter for 2nd deriv \n",
    "    \n",
    "    Params: image_a0 = the upsampled image  \n",
    "    \n",
    "    Return: Sobel_x, Sobel_y, Sobel_z = 3D arrays of the 1st gradient of the image using the Sobel filter\n",
    "            Laplacian_x, Laplacian_y, Laplacian_z = 3D arrays of the 2nd gradient of the image using the Laplacian filter\n",
    "'''\n",
    "def compute_gradient_images(image_a0):\n",
    "    \n",
    "    Laplacian_x = np.zeros(shape = image_a0.shape)\n",
    "    Laplacian_y = np.zeros(shape = image_a0.shape)\n",
    "    Laplacian_z = np.zeros(shape = image_a0.shape)\n",
    "    \n",
    "    # Compute the first gradient images in each respective direction using the Sobel filter \n",
    "    Sobel_x = sobel(image_a0, 0)\n",
    "    Sobel_y = sobel(image_a0, 1)\n",
    "    Sobel_z = sobel(image_a0, 2)\n",
    "    \n",
    "    # Compute the second gradient images in each respective direction using the Laplacian filter\n",
    "    for i in range(image_a0.shape[0]):\n",
    "        Laplacian_x[i,:,:] = laplace(image_a0[i,:,:])\n",
    "        Laplacian_y[:,i,:] = laplace(image_a0[:,i,:])\n",
    "    \n",
    "    for j in range(image_a0.shape[2]):\n",
    "        Laplacian_z[:,:,j] = laplace(image_a0[:,:,j])\n",
    "    \n",
    "    return Sobel_x, Sobel_y, Sobel_z, Laplacian_x, Laplacian_y, Laplacian_z\n",
    "\n",
    "\n",
    "'''\n",
    "    Concatenates patches of size 4x4xZ (size of Z-axis) from the 6 gradient images to form feature vectors\n",
    "    \n",
    "    Params: Sobel_x, Sobel_y, Sobel_z, Laplacian_x, Laplacian_y, Laplacian_z = arrays generated from compute_gradient_images\n",
    "    \n",
    "    Return: feature_array = 2D Array of feature vectors, where each row corresponds to a feature per image patch\n",
    "'''\n",
    "def extract_features(Sobel_x, Sobel_y, Sobel_z, Laplacian_x, Laplacian_y, Laplacian_z):\n",
    "    \n",
    "    x = int(Sobel_x.shape[0]/4)\n",
    "    y = int(Sobel_x.shape[1]/4)\n",
    "    feature_array = np.zeros(shape = (x*y, 6*4*4*Sobel_x.shape[2]))\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(0, Sobel_x.shape[1], 4):\n",
    "        for j in range(0, Sobel_x.shape[0], 4):\n",
    "            Sobel_x_feature = Sobel_x[j:(j+4), i:(i+4), :].flatten()\n",
    "            Sobel_y_feature = Sobel_y[j:(j+4), i:(i+4), :].flatten()\n",
    "            Sobel_z_feature = Sobel_z[j:(j+4), i:(i+4), :].flatten()\n",
    "            Laplacian_x_feature = Laplacian_x[j:(j+4), i:(i+4), :].flatten()\n",
    "            Laplacian_y_feature = Laplacian_y[j:(j+4), i:(i+4), :].flatten()\n",
    "            Laplacian_z_feature = Laplacian_z[j:(j+4), i:(i+4), :].flatten()\n",
    "            \n",
    "            feature_per_patch = np.concatenate((Sobel_x_feature, Sobel_y_feature, Sobel_z_feature,\n",
    "                                                Laplacian_x_feature, Laplacian_y_feature, Laplacian_z_feature))\n",
    "            feature_array[k, :] = feature_per_patch\n",
    "            \n",
    "            if k % 100 == 0:\n",
    "                print('We are on iteration : ' + str(k))\n",
    "            k += 1\n",
    "            \n",
    "    print(k)\n",
    "    \n",
    "    return feature_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Compresses input features by a magnitude of ~100 using PCA - use number_of_PCs = int(feature_array.shape[1]/100)\n",
    "    \n",
    "    Params: feature_array = 2D Array of concatenated patch features from the Sabel and Laplacian gradients in each direction\n",
    "            number_of_PCs = number of principal components you want to keep (a hyperparameter we can tweak)\n",
    "            \n",
    "    Return: reduced features = features that are reduced to a dimension of number_of_PCs\n",
    "'''\n",
    "def compress_features(feature_array, number_of_PCs):\n",
    "    \n",
    "    reduced_features = PCA(n_components=number_of_PCs).fit_transform(feature_array)\n",
    "    return reduced_features\n",
    "\n",
    "\n",
    "'''\n",
    "    Computes the difference image y_a0d = y_0 - y_a0\n",
    "    \n",
    "    Params: rotated_image = upsampled LR image that is rotated by rotation matrix\n",
    "            image_a0 = upsampled LR image that is convolved with the rotated kernel\n",
    "            \n",
    "    Return: difference_image_patches = patches of size 4x4xrotated_image.shape[2] from the difference image y_a0d\n",
    "'''\n",
    "def get_difference_image_patches(rotated_image, image_a0):\n",
    "    \n",
    "    difference_image = rotated_image - image_a0\n",
    "    x = int(difference_image.shape[0]/4)\n",
    "    y = int(difference_image.shape[1]/4)\n",
    "    difference_image_patches = np.zeros(shape = (x*y, 4*4*difference_image.shape[2]))\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(0, difference_image.shape[1], 4):\n",
    "        for j in range(0, difference_image.shape[0], 4):\n",
    "            difference_image_patches[k, :] = difference_image[j:(j+4), i:(i+4), :].flatten()\n",
    "            if k % 100 == 0:\n",
    "                print('We are on iteration : ' + str(k))\n",
    "            k += 1\n",
    "            \n",
    "    print(k)\n",
    "    \n",
    "    return difference_image_patches\n",
    "\n",
    "\n",
    "'''\n",
    "    Get feature clusters using K-Means: original paper uses K-SVD but this implementation is quite complicated\n",
    "    \n",
    "    Params: reduced_features = matrix of PCA-reduced feature vectors\n",
    "            number_of_clusters = number of clusters we want to use - we use 128 since that is what the paper uses\n",
    "            \n",
    "    Return: labels = array for which feature is matched to which cluster\n",
    "'''\n",
    "def cluster_with_kmeans(reduced_features, number_of_clusters):\n",
    "        \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=number_of_clusters, random_state=124)\n",
    "    kmeans.fit(reduced_features)\n",
    "    \n",
    "    labels = kmeans.predict(reduced_features)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "'''\n",
    "    Compute projection matrices P_k for each cluster k that minimizes \n",
    "    the least squares distance P_k*feature_vec = difference_image_patches\n",
    "    \n",
    "    Params: reduced_features = matrix of PCA-reduced feature vectors\n",
    "            different_image_patches = patches of the differenced image\n",
    "            labels = K-means or K-SVD generated groupings\n",
    "    \n",
    "    Return: projection_matrices = numpy array of size 128 x \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rect = np.zeros(shape = (10, 10))\n",
    "rect[2:8, 2:8] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_r, test_a0, test_s0 = generate_rotated_images(LR_img_interp, rect, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_Sobel_x, test_Sobel_y, test_Sobel_z, test_Laplace_x, test_Laplace_y, test_Laplace_z = compute_gradient_images(test_a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on iteration : 0\n",
      "We are on iteration : 100\n",
      "We are on iteration : 200\n",
      "We are on iteration : 300\n",
      "We are on iteration : 400\n",
      "We are on iteration : 500\n",
      "We are on iteration : 600\n",
      "We are on iteration : 700\n",
      "We are on iteration : 800\n",
      "We are on iteration : 900\n",
      "We are on iteration : 1000\n",
      "We are on iteration : 1100\n",
      "We are on iteration : 1200\n",
      "We are on iteration : 1300\n",
      "We are on iteration : 1400\n",
      "We are on iteration : 1500\n",
      "We are on iteration : 1600\n",
      "We are on iteration : 1700\n",
      "We are on iteration : 1800\n",
      "We are on iteration : 1900\n",
      "We are on iteration : 2000\n",
      "We are on iteration : 2100\n",
      "We are on iteration : 2200\n",
      "We are on iteration : 2300\n",
      "We are on iteration : 2400\n",
      "We are on iteration : 2500\n",
      "We are on iteration : 2600\n",
      "We are on iteration : 2700\n",
      "We are on iteration : 2800\n",
      "We are on iteration : 2900\n",
      "We are on iteration : 3000\n",
      "We are on iteration : 3100\n",
      "We are on iteration : 3200\n",
      "We are on iteration : 3300\n",
      "We are on iteration : 3400\n",
      "We are on iteration : 3500\n",
      "We are on iteration : 3600\n",
      "We are on iteration : 3700\n",
      "We are on iteration : 3800\n",
      "We are on iteration : 3900\n",
      "We are on iteration : 4000\n",
      "We are on iteration : 4100\n",
      "We are on iteration : 4200\n",
      "We are on iteration : 4300\n",
      "We are on iteration : 4400\n",
      "We are on iteration : 4500\n",
      "We are on iteration : 4600\n",
      "We are on iteration : 4700\n",
      "We are on iteration : 4800\n",
      "We are on iteration : 4900\n",
      "We are on iteration : 5000\n",
      "We are on iteration : 5100\n",
      "We are on iteration : 5200\n",
      "We are on iteration : 5300\n",
      "We are on iteration : 5400\n",
      "We are on iteration : 5500\n",
      "We are on iteration : 5600\n",
      "We are on iteration : 5700\n",
      "We are on iteration : 5800\n",
      "We are on iteration : 5900\n",
      "We are on iteration : 6000\n",
      "We are on iteration : 6100\n",
      "We are on iteration : 6200\n",
      "We are on iteration : 6300\n",
      "We are on iteration : 6400\n",
      "We are on iteration : 6500\n",
      "We are on iteration : 6600\n",
      "We are on iteration : 6700\n",
      "We are on iteration : 6800\n",
      "We are on iteration : 6900\n",
      "We are on iteration : 7000\n",
      "We are on iteration : 7100\n",
      "We are on iteration : 7200\n",
      "We are on iteration : 7300\n",
      "We are on iteration : 7400\n",
      "We are on iteration : 7500\n",
      "We are on iteration : 7600\n",
      "We are on iteration : 7700\n",
      "We are on iteration : 7800\n",
      "We are on iteration : 7900\n",
      "We are on iteration : 8000\n",
      "We are on iteration : 8100\n",
      "We are on iteration : 8200\n",
      "We are on iteration : 8300\n",
      "We are on iteration : 8400\n",
      "We are on iteration : 8500\n",
      "We are on iteration : 8600\n",
      "We are on iteration : 8700\n",
      "We are on iteration : 8800\n",
      "We are on iteration : 8900\n",
      "We are on iteration : 9000\n",
      "We are on iteration : 9100\n",
      "We are on iteration : 9200\n",
      "We are on iteration : 9300\n",
      "We are on iteration : 9400\n",
      "We are on iteration : 9500\n",
      "We are on iteration : 9600\n",
      "We are on iteration : 9700\n",
      "We are on iteration : 9800\n",
      "We are on iteration : 9900\n",
      "We are on iteration : 10000\n",
      "We are on iteration : 10100\n",
      "We are on iteration : 10200\n",
      "We are on iteration : 10300\n",
      "We are on iteration : 10400\n",
      "We are on iteration : 10500\n",
      "We are on iteration : 10600\n",
      "We are on iteration : 10700\n",
      "We are on iteration : 10800\n",
      "We are on iteration : 10900\n",
      "We are on iteration : 11000\n",
      "We are on iteration : 11100\n",
      "We are on iteration : 11200\n",
      "We are on iteration : 11300\n",
      "We are on iteration : 11400\n",
      "We are on iteration : 11500\n",
      "We are on iteration : 11600\n",
      "We are on iteration : 11700\n",
      "We are on iteration : 11800\n",
      "We are on iteration : 11900\n",
      "We are on iteration : 12000\n",
      "We are on iteration : 12100\n",
      "We are on iteration : 12200\n",
      "We are on iteration : 12300\n",
      "We are on iteration : 12400\n",
      "12432\n"
     ]
    }
   ],
   "source": [
    "test_features = extract_features(test_Sobel_x, test_Sobel_y, test_Sobel_z, test_Laplace_x, test_Laplace_y, test_Laplace_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_compressed_features = compress_features(test_features, int(test_features.shape[1]/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12432, 36)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_compressed_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on iteration : 0\n",
      "We are on iteration : 100\n",
      "We are on iteration : 200\n",
      "We are on iteration : 300\n",
      "We are on iteration : 400\n",
      "We are on iteration : 500\n",
      "We are on iteration : 600\n",
      "We are on iteration : 700\n",
      "We are on iteration : 800\n",
      "We are on iteration : 900\n",
      "We are on iteration : 1000\n",
      "We are on iteration : 1100\n",
      "We are on iteration : 1200\n",
      "We are on iteration : 1300\n",
      "We are on iteration : 1400\n",
      "We are on iteration : 1500\n",
      "We are on iteration : 1600\n",
      "We are on iteration : 1700\n",
      "We are on iteration : 1800\n",
      "We are on iteration : 1900\n",
      "We are on iteration : 2000\n",
      "We are on iteration : 2100\n",
      "We are on iteration : 2200\n",
      "We are on iteration : 2300\n",
      "We are on iteration : 2400\n",
      "We are on iteration : 2500\n",
      "We are on iteration : 2600\n",
      "We are on iteration : 2700\n",
      "We are on iteration : 2800\n",
      "We are on iteration : 2900\n",
      "We are on iteration : 3000\n",
      "We are on iteration : 3100\n",
      "We are on iteration : 3200\n",
      "We are on iteration : 3300\n",
      "We are on iteration : 3400\n",
      "We are on iteration : 3500\n",
      "We are on iteration : 3600\n",
      "We are on iteration : 3700\n",
      "We are on iteration : 3800\n",
      "We are on iteration : 3900\n",
      "We are on iteration : 4000\n",
      "We are on iteration : 4100\n",
      "We are on iteration : 4200\n",
      "We are on iteration : 4300\n",
      "We are on iteration : 4400\n",
      "We are on iteration : 4500\n",
      "We are on iteration : 4600\n",
      "We are on iteration : 4700\n",
      "We are on iteration : 4800\n",
      "We are on iteration : 4900\n",
      "We are on iteration : 5000\n",
      "We are on iteration : 5100\n",
      "We are on iteration : 5200\n",
      "We are on iteration : 5300\n",
      "We are on iteration : 5400\n",
      "We are on iteration : 5500\n",
      "We are on iteration : 5600\n",
      "We are on iteration : 5700\n",
      "We are on iteration : 5800\n",
      "We are on iteration : 5900\n",
      "We are on iteration : 6000\n",
      "We are on iteration : 6100\n",
      "We are on iteration : 6200\n",
      "We are on iteration : 6300\n",
      "We are on iteration : 6400\n",
      "We are on iteration : 6500\n",
      "We are on iteration : 6600\n",
      "We are on iteration : 6700\n",
      "We are on iteration : 6800\n",
      "We are on iteration : 6900\n",
      "We are on iteration : 7000\n",
      "We are on iteration : 7100\n",
      "We are on iteration : 7200\n",
      "We are on iteration : 7300\n",
      "We are on iteration : 7400\n",
      "We are on iteration : 7500\n",
      "We are on iteration : 7600\n",
      "We are on iteration : 7700\n",
      "We are on iteration : 7800\n",
      "We are on iteration : 7900\n",
      "We are on iteration : 8000\n",
      "We are on iteration : 8100\n",
      "We are on iteration : 8200\n",
      "We are on iteration : 8300\n",
      "We are on iteration : 8400\n",
      "We are on iteration : 8500\n",
      "We are on iteration : 8600\n",
      "We are on iteration : 8700\n",
      "We are on iteration : 8800\n",
      "We are on iteration : 8900\n",
      "We are on iteration : 9000\n",
      "We are on iteration : 9100\n",
      "We are on iteration : 9200\n",
      "We are on iteration : 9300\n",
      "We are on iteration : 9400\n",
      "We are on iteration : 9500\n",
      "We are on iteration : 9600\n",
      "We are on iteration : 9700\n",
      "We are on iteration : 9800\n",
      "We are on iteration : 9900\n",
      "We are on iteration : 10000\n",
      "We are on iteration : 10100\n",
      "We are on iteration : 10200\n",
      "We are on iteration : 10300\n",
      "We are on iteration : 10400\n",
      "We are on iteration : 10500\n",
      "We are on iteration : 10600\n",
      "We are on iteration : 10700\n",
      "We are on iteration : 10800\n",
      "We are on iteration : 10900\n",
      "We are on iteration : 11000\n",
      "We are on iteration : 11100\n",
      "We are on iteration : 11200\n",
      "We are on iteration : 11300\n",
      "We are on iteration : 11400\n",
      "We are on iteration : 11500\n",
      "We are on iteration : 11600\n",
      "We are on iteration : 11700\n",
      "We are on iteration : 11800\n",
      "We are on iteration : 11900\n",
      "We are on iteration : 12000\n",
      "We are on iteration : 12100\n",
      "We are on iteration : 12200\n",
      "We are on iteration : 12300\n",
      "We are on iteration : 12400\n",
      "12432\n"
     ]
    }
   ],
   "source": [
    "test_difference_image_patches = get_difference_image_patches(test_r, test_a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = cluster_with_kmeans(test_compressed_features, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]),\n",
       " array([  79, 2556,   56,   15,  256,   55,  437,   45,   75,   92,   29,\n",
       "         116,   28,  134,  122,   25,  231,   60,  239,   22,   41,   93,\n",
       "          39,   59,   32,  150,  359,   66,  115,   97,   51,  191,    9,\n",
       "          53,   54,   78,  102,  166,   39,  128,   47,   23,   32,   18,\n",
       "          47,   30,  132,  176,   89,  237,  140,   67,  128,   16,  138,\n",
       "          98,   15,  122,   37,  112,   44,   87,   24,   20,   30,   22,\n",
       "          13,  183,   77,  122,   17,   86,   38,   29,   22,   15,   33,\n",
       "          19,  151,   69,   71,   56,  155,   95,   38,   20,   18,   94,\n",
       "          92,  192,   27,   80,   38,   32,   25,  152,   42,  114,   29,\n",
       "          69,   16,   13,  168,  121,   19,   11,   11,   68,    7,   26,\n",
       "          56,   65,   66,   36,   19,   67,   24,   22,  147,   53,   30,\n",
       "          15,   47,  178,   13,  124,  143,   29], dtype=int64))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dbscan = cluster_with_DBScan(test_compressed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
